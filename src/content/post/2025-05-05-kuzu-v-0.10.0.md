---
slug: "kuzu-0.10.0-release"
title: "Kuzu 0.10.0 Release"
description: "Release announcement for Kuzu 0.10.0, introducing graph data science extension"
pubDate: "May 7 2025"
heroImage: "/img/default.png"
categories: ["release"]
authors: ["team"]
tags: ["cypher"]
---

Welcome back! It's the start of summer in ðŸ‡¨ðŸ‡¦, and we're excited to kick it off with the release of Kuzu 0.10.0!
The standout new feature in this release is our new graph algorithms extension. 
Graph algorithms are useful for extracting meaningful insights from connected data. Whether you're detecting fraud
patterns in financial transactions, optimizing supply chain networks, or analyzing social media interactions,
running graph algorithms natively in Kuzu can help reveal patterns and make data-driven decisions from your graphs.

Along with the graph algorithms extension, we've also added support for scanning compressed CSV files,
added a Neo4j migration extension, and as always, included performance optimizations to speed up recursive
queries, JSON scans, and more.

## Graph algorithms

In this section, we'll highlight the key features of the graph algorithms extension:

- **Scalable**: Graph algorithms are executed natively in Kuzu through a parallel framework based on the [Ligra paper](https://jshun.csail.mit.edu/ligra.pdf),
allowing you to scale your algorithms on very large graphs.
- **Disk-based**: The algorithms are disk-based and implemented within Kuzu storage engine, so you don't need to worry about memory
limits as you scale your graph workloads.
- **Native cypher integration**: Combine graph algorithms with arbitrary cypher pattern matching, so you don't need to move your subgraphs
out to other systems and bring them back into Kuzu -- everything is in one place!

The initial release includes the following algorithms:

- Weakly connected components
- Strongly connected components (a parallel BFS-based and a single-thread DFS-based implementation)
- PageRank
- K-Core decomposition
- Louvain
- (All) Weighted shortest path

We plan on adding more algorithms that are commonly used in graph analytics in future releases.

### Performance benchmarks

We'll demonstrate the performance and scalability of our graph algorithms in Kuzu on multiple
benchmark datasets and thread configurations. The following three datasets are from different domains
ranging from thousands to billions of edges.

| Dataset | # Nodes | # Edges | Raw File Size |
|---------|---------|---------|---------------|
| soc-sign-bitcoin-otc | 5K | 35K | 1MB |
| soc-LiveJournal1 | 4.8M | 68M | 1.1GB |
| datagen-sf10k | 100M | 9.4B | 294.3GB |

We report the end-to-end runtimes on a machine with 2xAMD EPYC 9J14 CPUs and 768GB RAM, using 4, 16 and
64 threads for execution.

#### soc-sign-bitcoin-otc

| Algorithm | 4 threads | 16 threads | 64 threads |
|-----------|-----------|------------|------------|
| WCC |  12.2ms | 15.7ms | 20.0ms |
| SCC | 39.3ms | 46.7ms | 49.6ms |
| SCC-ko | 15.5ms | 38.1ms | 34.5ms |
| PageRank | 50.1ms | 51.0ms | 49.6ms |
| K-Core | 181.3ms | 207.8ms | 213.0ms |
| Louvain | 123.0ms | 137.2ms | 143.7ms |
| WSP | 16.4ms | 16.8ms | 19.2ms |

#### soc-LiveJournal1

| Algorithm | 4 threads | 16 threads | 64 threads |
|-----------|-----------|------------|------------|
| WCC | 3.6s  | 0.9s | 0.3s |
| SCC | 9.6s | 2.6s | 0.9s |
| SCC-ko | 8.3s | 8.2s | 8.2s |
| PageRank | 19.9s | 6.9s | 5.1s |
| K-Core | 46.7s | 13.3s | 9.2s |
| Louvain | 102.2s | 42.7s | 21.2s |
| WSP | 13.6s | 3.8s | 1.1s |

#### datagen-sf10k

[^1]: Louvain algorithm requires more than 256GB of memory on datagen-sf10k so we omit Louvain in this dataset.

| Algorithm | 4 threads | 16 threads | 64 threads |
|-----------|-----------|------------|------------|
| WCC | 201.4s | 54.3s | 19.7s |
| SCC |  |  | 849.3s |
| SCC-ko | 273.5s | 271.2s | 280.0s |
| PageRank | 992.5s| 299.4s | 146.5s |
| K-Core | 585.6s | 151.8s | 52.7s |
| WSP | 4.8s | 2.5s | 0.7s |

### Using graph algorithms

All algorithms, except for that [(all) weighted shortest paths](http://docs.kuzudb.com/cypher/query-clauses/match#shortest-path) which is provided as built-in, are available via the [`algo` extension](http://docs.kuzudb.com/extensions/algos). 
Let's look at example usage of graph algorithms using the well-known LDBC SNB dataset.
The example beloew finds top 10 influencers based on the `(person)-[:knows]->(person)` subgraph and extracts all the posts they've commented on.

```cypher
// Install graph algorthm extension
INSTALL algo;
LOAD algo;

// Create a projected graph with person and knows tables.
CALL create_projected_graph(
    'KnowsGraph', 
    ['person'], 
    ['knows']
);

// Run page rank on projected graph to find the top 10 influencers.
// Then traverse `postHasCreator` to extract all posts
CALL page_rank('KnowsGraph')
WITH node AS person, rank
ORDER BY rank DESC
LIMIT 10
MATCH (person)<-[:postHasCreator]-(post:Post)
RETURN person, post;
```

We first install and load the `algo` extension. Then, we create a projected graph from the `person` and `knows` tables,
on which the algorithm is executed. The projected graph is a subgraph that contains only the nodes and
relationships specified. It is evaluated only when the algorithm is executed. Kuzu does not materialize projected
graphs in memory and all data is scanned from disk on-the-fly. This allows for graph updates from new incoming data
to be utilized if the algorithm is re-run at a later time.

### Using graph algorithms on filtered graphs

Graph algorithms can also run on a subset of table records using filtered graph. 
From the example above, we can find influencers within a certain age group, e.g. 18-24, with a
filtered projected graph.

```cypher
// Create a filtered graph selecting person within the age group
CALL create_projected_graph(
    'FilteredKnowsGraph', 
    { 'person': 'n.birthday >= date("2001-01-01") AND n.birthday <= date("2007-12-31")' },
    ['knows']
);

// Run page rank on filtered projected graph
CALL page_rank('FilteredKnowsGraph')
WITH node AS person, rank
ORDER BY rank DESC
LIMIT 10
MATCH (person)<-[:postHasCreator]-(post:Post)
RETURN person, post;
```

Using these techniques, we can run graph algorithms efficiently and scalably all within Kuzu. If you're
interested in using Kuzu's graph algorithms, give this a try, and check out the [docs](http://docs.kuzudb.com/extensions/algos) here.

## Neo4j migration extension 

A lot of Kuzu users have previously used or are using Neo4j. To make it easier to migrate graph data from Neo4j to Kuzu, we introduce a [`Neo4j`](http://docs.kuzudb.com/extensions/neo4j) extension that can automatically import nodes and relationships from Neo4j to Kuzu databases.

Install the `neo4j` extension in Kuzu and then run the following query that specifies the Neo4j database host, username, password, and the node and relationship labels you want to migrate.

```cypher
CALL neo4j_migrate(
    'host_name',
    'user_name',
    'password',
    ['node_label_1', 'node_label_2', ...],
    ['rel_label_1', 'rel_label_2', ...]
)
```

Note that the Neo4j migration functionality depends on the APOC extension to be installed in your deployment of Neo4j, so ensure that it's installed
before running the migration into Kuzu. You can find more details on setting up the APOC extension on Neo4j desktop or server [here](http://docs.kuzudb.com/extensions/neo4j#set-up-neo4j-apoc-extension). Read more on Kuzu's Neo4j extension [here](http://docs.kuzudb.com/extensions/neo4j).

## Scan compressed CSV

Our users commonly requested that their compressed CSV files be directly scanned or copied into Kuzu. We're happy to add support
for scanning or copying `.gzip.csv` files directly into Kuzu starting from this release.

Consider a `user.csv` file. Let's first zip this file to a new file named `user.csv.gz` as follows:

```shell
gzip -k user.csv
```

The compressed CSV file can then be scanned or copied into a Kuzu table:
```cypher
// scan
LOAD FROM 'user.csv.gz' RETURN *;
// copy
COPY User FROM 'user.csv.gz';
```

Storing compressed CSV files in Kuzu is useful when importing data from external systems that store
data in compressed CSV format, such as object stores. See [here](https://docs.kuzudb.com/import/csv/#compressed-csv-files)
for more details on this feature.

## Android support

We're excited to now support Android devices with ARMv8-A architecture through our Java API. Developers can
now build mobile applications that leverage Kuzu's graph database capabilities directly on Android devices.
The precompiled binaries are compiled targetting [API level 21](https://developer.android.com/tools/releases/platforms).

## Performance Improvements

You'll notice that Kuzu is now faster than ever, particularly for recursive queries and JSON scans. Additionally,
this release includes a new free space management mechanism to help reduce disk space usage, so you can keep your disk utilization in check.

### Free Space Management

Reusing disk space usage has been a long awaited feature in Kuzu.
Up until this release, databases became bloated after frequent data modifications, such as updates and deletions.
We introduce a new free space management mechanism that is able to reclaim free space in three key scenarios:
1. When tables are dropped
2. When tuples within a node group are all deleted
3. When column chunks are rewritten due to updates or insertions

The disk space reclamation process occurs automatically during the `CHECKPOINT` phase, and has minimal impact on regular transactions.
So you shouldn't notice any performance overhead due to this feature.

Note that:
- The current implementation focuses on managing free space in the `data.kz` file, which stores main data of node and rel tables. We plan to extend this functionality to index files in future releases.
- We never shrink our `data.kz` file. Instead, we keep track of free space within the file and try to reuse it during future allocations.

To demonstrate the effectiveness of our new free space management mechanism, we conducted a micro-benchmark using the LDBC dataset at scale factor 100.
We compared the disk space usage between v0.9.0 and v0.10.0 across three different workloads:
1. **Multi COPY**: We partition the `person` csv file into `10` partitions, each of which is saved as a csv file. We copy each partitioned csv file one at a time, and report the final size of `data.kz` file.
2. **Drop Tables**: We create a node table `person`, copy tuples into the table, drop the table, and perform `CHECKPOINT`. We repeat these operations for 5 times, and report the final size of `data.kz` file.
3. **Bulk Deletions**: We create a node table `person`, copy tuples into the table, delete all tuples from the table, and perform `CHECKPOINT`. We repeat these operations for 5 times, and report the final size of `data.kz` file.

| Workloads | 0.9.0 | 0.10.0 |
| --------- | ----- | ------ |
| Multi COPY | 32MB | 20MB |
| Delete | 85MB | 20MB |
| Drop | 75MB | 18MB |

No matter the number of operations, the size of the `data.kz` file is stable in v0.10.0 (because it's reclaiming free space on disk),
whereas the repeated operations in v0.9.0 cause the size of the `data.kz` file to grow.

### Recursive queries

In v0.9.0, we had introduced a parallel framework for recursive queries aiming to mitigate the long tail problem when recursive queries access a highly skewed node, i.e. node with high degree. Although it improved performance in these scenarios, it blindly allocated a concurrent data structure
whose size was linear to the number of nodes in relevant tables. This incurred a performance overhead when running a _small_ recursive query
on _very large_ database in which case, the allocation became the bottleneck. 

In v0.9.0, on LDBC100 with 220M `Comment` records, a simple index nested loop join query took about **1ms** but its equivalent recursive query takes **300ms** due to the large size of the `Comment` table.

```cypher
// Non-recursive
MATCH (:Comment {id:<id>})-[:replyOf]->(:Comment)
// Recursive
MATCH (:Comment {id:<id>})-[:replyOf*1..1]->(:Comment) // 300ms
``` 

In v0.10.0, we eliminate the bottleneck by starting with a small allocation and dynamically growing the data structure.
This brings the recursive query performance back to **1ms**, on par with the non-recursive query.

| Query | 0.9.0 | 0.10.0 |
| ----- | ----- | ------ |
| Non-recursive | 1ms   | 1ms    |
| Recursive     | 300ms | 1ms    |

That's a 300x improvement in performance!

### JSON scan

Importing JSON data into Kuzu is a common use case. In v0.10,0, we've significantly improved the performance
of JSON scanning. Below, we show a micro benchmark that scans LDBC-100 dataset in JSON format.

```cypher
INSTALL json;
LOAD json;  
// Scan json file
LOAD FROM 'ldbc100-file.json' RETURN *;
```

|  | 1 thread | 2 threads | 4 threads |
|---------|----------|-----------|-----------|
| v0.9    | 190s    | 99s      | 52s      |
| v0.10   | 56s    | 27s      | 15s     |

In general, you should see a significant performance improvement when scanning JSON files.

## Closing remarks

At Kuzu, we want to make it easier for developers to work with large graphs, and with the addition of
a fully native graph algorithms extension, we now provide a batteries-included feature set
for all your analytical graph query workloads. All these new features and performance improvements have been
a long time in the making, and we're excited to see users push the boundaries
of what's possible with graph databases. If you're working with large graphs and want to run
graph algorithms such as PageRank, give the latest release a try!

We recently crossed 2000 stars [on GitHub](https://github.com/kuzudb/kuzu), and we're seeing a lot
of activity on our [Discord server](https://kuzudb.com/chat) than ever before. Thank you all for your
questions and feedback -- we're always looking for ways to make Kuzu even better. Keep them coming,
and see you in the next release!

-- The Kuzu Team