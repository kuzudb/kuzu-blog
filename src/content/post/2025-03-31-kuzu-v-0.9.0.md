---
slug: "kuzu-0.9.0-release"
title: "Kuzu 0.9.0 Release"
description: "Release announcement for Kuzu 0.9.0"
pubDate: "Mar 31 2025"
heroImage: "/img/default.png"
categories: ["release"]
authors: ["team"]
tags: ["cypher"]
---


## Vector Index
As there is a growing demand for vector similarity searches in databases, we are excited to announce our new `VECTOR` extension, which allows you to perform similarity search over vector data in Kuzu.

We adopt the [hierachical navigable small world (HNSW)](https://dl.acm.org/doi/10.1109/tpami.2018.2889473) vector index design with two layers.
The lower layer consists of all vectors (each vector can be viewed as a node) and a set of edges that connect pairs of vectors that are close to each other.
The upper layer is same as the lower layer except for that it only consists of a subset of the vectors that are sampled from the full set.
As each layer is essential a graph structure, which is native to Kuzu, we store each layer as a relationship table in Kuzu.
In this way, we make use of Kuzu's native storage and query capabilities to store and search the index.

To start using our vector index, you have to first install and load the extension:
```cypher
INSTALL VECTOR;
LOAD VECTOR;
```

In the extension, we provide three basic functions to create, query, and drop a vector index:
```cypher
CALL CREATE_VECTOR_INDEX(
    'table_name',      // Name of the table containing the vector column
    'index_name',      // Name to identify the vector index
    'column_name',     // Name of the column containing vector embeddings
    [option_name := option_value]  // Optional parameters for index configuration
);
CALL QUERY_VECTOR_INDEX(
    'table_name',      // Name of the table
    'index_name',      // Name of the vector index
    query_vector,      // Vector to search for
    k,                 // Number of nearest neighbors to return
    [option_name := option_value]  // Optional parameters
) RETURN node.id ORDER BY distance;
CALL DROP_VECTOR_INDEX('table_name', 'index_name');
```

We use an example through our Python API below to demonstrate how these functions work.
First, we populate the database with some sample data, consisting of two node tables `Book` and `Publisher`, and a relationship table `PublishedBy`.
```python
# pip install sentence-transformers
# pip install kuzu
import kuzu
from sentence_transformers import SentenceTransformer
# Load a pre-trained embedding generation model. https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
model = SentenceTransformer("all-MiniLM-L6-v2")

db = kuzu.Database()
conn = kuzu.Connection(db)
conn.execute("INSTALL VECTOR;")
conn.execute("LOAD VECTOR;")
# Create tables Book, Publisher, and PublishedBy
conn.execute("CREATE NODE TABLE Book(id SERIAL PRIMARY KEY, title STRING, title_embedding FLOAT[384]);")
conn.execute("CREATE NODE TABLE Publisher(name STRING PRIMARY KEY);")
conn.execute("CREATE REL TABLE PublishedBy(FROM Book TO Publisher, published_year INT64);")
titles = ["The Quantum World", "Chronicles of the Universe", "Learning Machines", "Echoes of the Past", "The Dragon's Call"]
publishers = ["Harvard University Press", "Independent Publisher", "Pearson", "McGraw-Hill Ryerson", "O'Reilly"]
published_years = [2004, 2022, 2019, 2010, 2015]
# Create nodes for Book and Publisher
for title in titles:
    # Convert title to a 384-dimensional embedding vector
    embeddings = model.encode(title).tolist()
    conn.execute("""CREATE (b:Book {title: $title, title_embedding: $embeddings});""", {"title": title, "embeddings": embeddings})
for publisher in publishers:
    conn.execute("""REATE (p:Publisher {name: $publisher});""", {"publisher": publisher})
# Create relationships between Book and Publisher
for title, publisher, published_year in zip(titles, publishers, published_years):
    conn.execute("""
        MATCH (b:Book {title: $title})
        MATCH (p:Publisher {name: $publisher})
        CREATE (b)-[:PUBLISHED_BY {published_year: $published_year}]->(p);
    """, {"title": title, "publisher": publisher, "published_year": published_year})
```
Then, we create a vector index on the `title_embedding` column of the `Book` table:
```python
# Create the index
conn.execute("CALL CREATE_VECTOR_INDEX('Book', 'title_vec_index', 'title_embedding');")
```
We now can perform a simple query to find the two books most similar to "The Quantum World" semantically.
```python
# Query the index and return the title
query_vector = model.encode("The Quantum World").tolist()
result = conn.execute("""
    CALL QUERY_VECTOR_INDEX('Book', 'title_vec_index', $query_vector, 2) RETURN nn.title ORDER BY distance;
    """, {"query_vector": query_vector})
print(result.get_as_df())
```

We can also combine the vector search with Cypher pattern matching to find publishers of the two books most similar to "The Quantum World".
```python
result = conn.execute("""
    CALL QUERY_VECTOR_INDEX('book', 'title_vec_index', $query_vector, 2) 
    WITH nn AS n, distance as dist 
    MATCH (n)-[:PUBLISHED_BY]->(p:Publisher) RETURN p.name ORDER BY dist;
    """, {"query_vector": query_vector})
print(result.get_as_df())
```

### Filtered Search
The `VECTOR` extension also supports performing vector search on a subset of records (filtered search). 
To perform a filtered search, first you need to define the filter through a projected graph with the following syntax:
```cypher
CALL CREATE_PROJECTED_GRAPH(
    'projected_graph_name', // Name of the projected graph
    {                      // Node tables to project
        'table_name': {
            'filter': 'predicate' // Optional predicate to filter nodes
        }
    },
    [                      // Relationship tables to project
        'table_name'
    ]
);
``` 

A projected graph is a subgraph (i.e., a subset of the original graph) that contains only the nodes and relationships that match the given table names and predicates. In this release, the projected graph is limited to single node table with simple filters on node properties.
We plan to allow more flexible filters that can take variables from Cypher pattern matching in the future.

For example, we can create a projected graph with a filter on `published_year` of `Book`, and then perform a filtered search combined with Cypher pattern matching to find publishers that publish books most similar to "The Quantum World" after 2010:
```python
# Create a projected graph with a filter on published_year of Book
conn.execute("CALL CREATE_PROJECTED_GRAPH('filtered_book', 
    {'Book': {'filter': 'n.published_year > 2010'}}, []);")
# Query the index on the projected graph
result = conn.execute("""
    CALL QUERY_VECTOR_INDEX('filtered_book', 'title_vec_index', $query_vector, 2) 
    WITH nn AS n, distance as dist 
    MATCH (n)-[:PUBLISHED_BY]->(p:Publisher) RETURN p.name ORDER BY dist;
    """, {"query_vector": query_vector})
print(result.get_as_df())
```

We've implemented a novel adaptive search algorithm that is predicate-agnostic with robust search performance. The idea is based on the research work done by [Gaurav Sehgal](https://www.linkedin.com/in/gaurav-sehgal-79abb9112/) and [Semih Salihoglu](https://cs.uwaterloo.ca/~ssalihog/), which is still under submission.
We will have a separate blog post to explain the technical details in the future.

### Performance
We first show the performance of index construction and query without any filters on [ann-benchmark](https://github.com/erikbern/ann-benchmarks).
The benchmark contains a set of datasets and test cases. 
We present the results on four datasets: `MNIST`, `SIFT`, `GIST`, and `Deep1B`, which cover various dimensions and scale.
The index is built with default settings (`mu := 30, ml := 60, efc := 200`).
We perform all queries in the ann benchmark on-disk with the default setting (`efs := 200`).
Each query is run 5 times, and we report the first one as cold and the average of the remaining 4 as warm.

<!--
 TODO: Update numbers.
-->

| Dataset | Dimension | Num tuples | Construction (s) | Search - Cold (ms) | Search - Warm (ms) |
| --- | --- | --- | --- | --- | --- |
| MNIST | 784 | 60,000 | 9.8 | 11.8 | 11.8 |
| SIFT | 128 | 100,000 | 11.6 | 10.7 | 10.7 |
| GIST | 960 | 100,000 | 587.1 |  |  |
| Deep1B | 96 | 9,990,000 | 1691.8 | 7.9 | 7.9 |

Next we show the performance of filtered search.
We apply a filter on the base table to control its selectivity to be 1%, 2%, 3%, 5%, 10%, 20%, 30%, 50%, 75% and 90%.
We randomly select 50 queries from the GIST query set, and for each selectivity, we apply the filter with a projected graph and perform the search.

| Selectivity (%) | Search - Cold (ms) | Search - Warm (ms) | Recall |
| --- | --- | --- | --- |
| 1 | 24.9 | 20.8 | 1.00 |
| 3 | 29.3 | 22.2 | 1.00 |
| 5 | 29.3 | 23.4 | 0.99 |
| 10 | 120.4 | 34.1 | 1.00 |
| 20 | 65.2 | 33.8 | 0.99 |
| 30 | 57.3 | 33.4 | 0.99 |
| 40 | 20.8 | 15.9 | 0.90 |
| 50 | 21.8 | 16.0 | 0.91 |
| 75 | 26.5 | 17.8 | 0.92 |
| 90 | 27.5 | 18.9 | 0.92 |

All experiments above are done on a Mac Mini desktop with M4 Pro chip, 64GB RAM, and 1TB SSD.

### Limitations
Our first release has the following limitations:
- The index is immutable after creation. You must drop and re-create the index to reflect changes in the underlying tables.
- We currently only support index over FLOAT array columns in Kuzu. More data type support are in our roadmap and will be added later.
- The index can only be created over a single column in node tables.


## Scan from Postgres with arbitrary SQL statements

In previous release, we introduced the [Postgres extension](https://docs.kuzudb.com/extensions/attach/rdbms/) which enabled scanning from PostgreSQL tables. This release further extends the capability with `SQL_QUERY` function, allowing users to execute arbitrary read-only SQL queries on attached PostgreSQL databases and retrieve the query result in kuzu.

Below shows an example of 
```sql
-- Attach a Postgres database
ATTACH 'dbname=university user=postgres host=localhost password=yourpassword port=5432' AS uw (dbtype postgres);
-- Scan from a Postgres query
CALL SQL_QUERY('uw', 'SELECT id, name, age FROM person WHERE age > 20') RETURN *;
-- Bulk insert from a Postgres query
CREATE NODE TABLE person(id INT PRIMARY KEY, name STRING, age INT);
COPY person FROM SQL_QUERY('uw', 'SELECT id, name, age FROM person WHERE age > 20');
```

## WASM with bundled extensions

In v0.8.0 we release a WebAssembly (WASM) version of Kuzu. One of the limitations of the WASM version was that it did not support extensions. This release ships a WASM version with several bundled extensions through static linking. The bundled extensions are
- Full-text search (fts)
- Json (json)
- Vector Index (vector)

## APIs and Ecosystem Integrations

### New Sync and Async APIs

Kuzu now provides both synchronous and asynchronous APIs for Python and Node.js bindings. For Python, synchronous API is the default choice while asynchronous API can be used in web frameworks like FastAPI. For Node.js, the asynchronous API is commonly used.


### Unity Catalog

### MCP

### Gdotv

## Performance Improvements

### Aggregation

Our team has been consistently focusing on improving query performance. In this release, we announce a major improvement on aggregation workloads, including distinct, hash aggregate and aggregate on distinct values. The performance again mainly comes from vectorizing computation and paralleling the final aggregation stage. We will present technical details in a separate blog post.

Benchmarks are from [ClickBench](https://github.com/ClickHouse/ClickBench/)'s benchmark suite, converted to cypher and run using a modified version of their benchmarking scripts (which uses our Python API to execute the queries and measures the total runtime of `kuzu.Connection.execute`).

The cold queries are run once with OS caches dropped before each query and in a new process.
The hot queries are run twice from the same process, database and connection as the cold query and the result is averaged.

The queries were run on a machine with 2x AMD EPYC 7551 (total 64 cores 128 threads) and 512GB RAM.

| Query   | 0.7.1 (cold)   | 0.8.0 (cold)   | 0.8.2 (cold)    | 0.9.0 (cold)     | 0.7.1 (hot)   | 0.8.0 (hot)      | 0.8.2 (hot)      | 0.9.0 (hot)        |
|---------|----------------|----------------|-----------------|------------------|---------------|------------------|------------------|--------------------|
| Q1      | 0.0791s        | 0.0534s        | 0.0597s         | 0.0658s          | 0.035s        | 0.0321s          | 0.0297s          | 0.0322s            |
| Q2      | 0.233s         | 0.248s         | 0.257s          | 0.233s           | 0.0209s       | 0.0196s          | 0.0175s          | 0.0199s            |
| Q3      | 0.539s         | 0.548s         | 0.538s          | 0.564s           | 0.0414s       | 0.0452s          | 0.0427s          | 0.0474s            |
| Q4      | 1.06s          | 1.06s          | 1.01s           | 1.02s            | 0.0709s       | 0.074s           | 0.0693s          | 0.0768s            |
| Q5      | 23.3s          | 23.3s          | 24.3s           | **1.25s** (19x)  | 21s           | 22.1s            | 22.8s            | **0.52s** (44x)    |
| Q6      | 20.4s          | 20.2s          | 13.6s           | **1.96s** (10x)  | 16.9s         | 17.1s            | 11s              | **0.373s** (46x)   |
| Q7      | 0.225s         | 0.235s         | 0.228s          | 0.247s           | 0.0192s       | 0.018s           | 0.0143s          | 0.017s             |
| Q8      | 0.273s         | 0.3s           | 0.285s          | 0.284s           | 0.0247s       | 0.033s           | 0.0361s          | 0.0454s            |
| Q9      | 201s           | **42.7s** (5x) | **3.51s** (57x) | **2.85s** (71x)  | 196s          | **35.4s** (6x)   | **2.46s** (79x)  | **1.96s** (100x)   |
| Q10     | 214s           | **51.5s** (4x) | **4.04s** (53x) | **3.25s** (66x)  | 206s          | **47.3s** (4x)   | **2.62s** (79x)  | **1.99s** (104x)   |
| Q11     | 19.2s          | 10.3s          | **1.87s** (10x) | **1.84s** (10x)  | 15s           | **6.4s** (2x)    | **0.681s** (22x) | **0.633s** (24x)   |
| Q12     | 32.4s          | **11.6s** (3x) | **2.04s** (16x) | **1.99s** (16x)  | 28.6s         | **6.88s** (4x)   | **0.684s** (42x) | **0.737s** (39x)   |
| Q13     | 5.47s          | **2.09s** (3x) | **1.96s** (3x)  | **2.05s** (3x)   | 3.58s         | **0.424s** (8x)  | **0.427s** (8x)  | **0.428s** (8x)    |
| Q14     | 59.3s          | **24.6s** (2x) | **3.19s** (19x) | **3.25s** (18x)  | 53s           | **17.3s** (3x)   | **0.903s** (59x) | **0.879s** (60x)   |
| Q15     | 5.91s          | **2.44s** (2x) | **2.2s** (3x)   | **2.15s** (3x)   | 4.03s         | **0.458s** (9x)  | **0.46s** (9x)   | **0.446s** (9x)    |
| Q16     | 7.08s          | **1.57s** (5x) | **1.45s** (5x)  | **1.49s** (5x)   | 5.99s         | **0.75s** (8x)   | **0.747s** (8x)  | **0.749s** (8x)    |
| Q17     | 11.2s          | **3.2s** (4x)  | **3.04s** (4x)  | **2.92s** (4x)   | 8.36s         | **1.01s** (8x)   | **1.06s** (8x)   | **1.05s** (8x)     |
| Q18     | 11.4s          | **3.03s** (4x) | **2.98s** (4x)  | **2.94s** (4x)   | 9.13s         | **0.922s** (10x) | **1.06s** (9x)   | **0.947s** (10x)   |
| Q19     | 28.6s          | **4.47s** (6x) | **4.19s** (7x)  | **4.29s** (7x)   | 21s           | **2.42s** (9x)   | **2.72s** (8x)   | **2.45s** (9x)     |
| Q20     | 1.01s          | 1.08s          | 0.959s          | 0.976s           | 0.0651s       | 0.0664s          | 0.0651s          | 0.065s             |
| Q21     | 20s            | 22.7s          | 21.1s           | **4.84s** (5x)   | 20.7s         | 23.6s            | 21.7s            | **0.634s** (37x)   |
| Q22     | 21.1s          | 23.6s          | 21.8s           | **10.2s** (2x)   | 21s           | 23.6s            | 21.5s            | **0.854s** (28x)   |
| Q23     | 1.1e+03s       | 1.13e+03s      | **19.1s** (59x) | **10.7s** (106x) | 1.09e+03s     | 1.11e+03s        | **18.5s** (60x)  | **0.949s** (1170x) |
| Q24     | 33.4s          | 34.2s          | 32.4s           | 24.7s            | 22.5s         | 24.6s            | 23.1s            | **3.24s** (8x)     |
| Q25     | 2.59s          | 2.55s          | 2.34s           | 2.43s            | 0.0631s       | 0.0647s          | 0.0666s          | 0.0653s            |
| Q26     | 1.73s          | 1.71s          | 1.52s           | 1.59s            | 0.077s        | 0.0714s          | 0.0838s          | 0.0785s            |
| Q27     | 2.63s          | 2.51s          | 2.48s           | 2.45s            | 0.0739s       | 0.0717s          | 0.0715s          | 0.0717s            |
| Q28     | 5.02s          | 5.37s          | 5.38s           | 5.42s            | 0.964s        | 1.01s            | 0.978s           | 0.971s             |
| Q29     | 4.33s          | 3.37s          | 4.77s           | 3.48s            | 4.01s         | 3.27s            | 4.57s            | 3.25s              |
| Q30     | hang           | hang           | hang            | hang             | hang          | hang             | hang             | hang               |
| Q31     | 6.51s          | 3.31s          | **3.08s** (2x)  | **3.21s** (2x)   | 3.47s         | **0.526s** (7x)  | **0.535s** (6x)  | **0.544s** (6x)    |
| Q32     | 9.26s          | **4.43s** (2x) | **4.04s** (2x)  | **3.87s** (2x)   | 5.36s         | **0.771s** (7x)  | **0.784s** (7x)  | **0.787s** (7x)    |
| Q33     | 66s            | **8.29s** (8x) | **8.32s** (8x)  | **8.55s** (8x)   | 48.7s         | **6.22s** (8x)   | **6.27s** (8x)   | **6.38s** (8x)     |
| Q34     | 24.1s          | **6.08s** (4x) | **6.26s** (4x)  | **6.14s** (4x)   | 15.8s         | **1.67s** (9x)   | **1.66s** (10x)  | **1.66s** (10x)    |
| Q35     | 22.5s          | **6.21s** (4x) | **6.02s** (4x)  | **6.35s** (4x)   | 17.9s         | **1.75s** (10x)  | **1.78s** (10x)  | **1.8s** (10x)     |
| Q36     | 9.93s          | **1.37s** (7x) | **1.35s** (7x)  | **1.31s** (8x)   | 7.84s         | **0.946s** (8x)  | **0.932s** (8x)  | **0.898s** (9x)    |
| Q37     | 1.65s          | 1.55s          | 1.5s            | 1.51s            | 0.191s        | 0.111s           | 0.135s           | 0.123s             |
| Q38     | 1.48s          | 1.42s          | 1.41s           | 1.46s            | 0.0941s       | 0.128s           | 0.126s           | 0.126s             |
| Q39     | 1.51s          | 1.59s          | 1.52s           | 1.49s            | 0.0834s       | 0.126s           | 0.121s           | 0.135s             |
| Q40     | 3.1s           | 3.27s          | 3s              | 2.88s            | 0.409s        | 0.32s            | 0.291s           | 0.275s             |
| Q41     | 0.904s         | 1.01s          | 0.826s          | 0.831s           | 0.0884s       | 0.077s           | 0.0869s          | 0.0937s            |
| Q42     | 0.768s         | 0.866s         | 0.728s          | 0.762s           | 0.061s        | 0.0786s          | 0.0765s          | 0.0717s            |
| Q43     | 0.519s         | 0.551s         | 0.474s          | 0.449s           | 0.0533s       | 0.0476s          | 0.055s           | 0.0541s            |

### Full-text search index creation

The performance of index creationg is also improved in this release. The following benchmark is conducted using `ms-passage` dataset with 8.8M documents that take 2.9GB in raw size and on a machine with 2 AMD EPYC 7551 CPUs with 64 cores and 409GB of memory. The result is shown as follows:

| v0.8.0 | v0.9.0 | Speedup |
|--------|--------| ------- |
| 460s   | 108s   | **4.3x**    |

