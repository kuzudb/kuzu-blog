---
slug: "kuzu-0.9.0-release"
title: "Kuzu 0.9.0 Release"
description: "Release announcement for Kuzu 0.9.0, including our brand new vector index!"
pubDate: "Apr 1 2025"
heroImage: "/img/default.png"
categories: ["release"]
authors: ["team"]
tags: ["cypher"]
---

It's been a flurry of activity since our last release, and we're delighted to
announce the release of Kuzu 0.9.0, whose most notable feature is a new
[`vector` extension](https://docs.kuzudb.com/extensions/vector/) that allows you to perform similarity
search over vector data fully within Kuzu. Read about this, and a host of other features and performance
improvements in this release, below!

## Vector Index

Vector search, supported by a vector index, enhances a graph database like Kuzu by enabling
similarity search over high-dimensional data (such as embeddings) which can be useful for applications
like Graph RAG or recommendation systems. Pairing vector search with graph search allows you to explore
relationships in structured data while also handling unstructured data effectively within a single
database, offering a practical blend of both capabilities.

Kuzu's vector index is offered as an [extension](https://docs.kuzudb.com/extensions/vector/)
and implements the well-known [hierachical navigable small world (HNSW)](https://dl.acm.org/doi/10.1109/tpami.2018.2889473)
index with two layers. Notably (and unlike many other systems), Kuzu's implementation of HNSW is **disk-based**,
so you can persist the vectors _and the index_ to disk and not have to worry about memory usage as you scale your graph.

In our HNSW graph, each vector can be viewed as a node, where the lower layer consists of all vectors
and a set of edges connecting pairs of vectors that are close to each other.
The upper layer is a coarser version of the lower layer that consists of a subset of the vectors
sampled from the full set in the lower layer. Each layer is essentially a native Kuzu graph structure,
so we're able to store them using relationship tables in Kuzu, allowing us to make use of Kuzu's fast querying capabilities.

The vector index in Kuzu implements a novel adaptive search algorithm that is predicate-agnostic, offering robust search performance,
and is based on recent research done by [Gaurav Sehgal](https://www.linkedin.com/in/gaurav-sehgal-79abb9112/)
and [Semih Salihoglu](https://cs.uwaterloo.ca/~ssalihog/). The work is currently under review for publication.
We'll publish another blog post to explain many more technical details about the implementation details,
so stay tuned!

For this release post, let's illustrate how the vector index works by using the example below in Python.
We'll use a sample dataset of books and their publishers, so that we can query the book titles by their similarity.
We have two node tables `Book` and `Publisher`, and one relationship table `PublishedBy`.
The [Sentence Transformers](https://sbert.net/) library is used to generate 384-dimensional embeddings
for the book titles.

```python
import kuzu
from sentence_transformers import SentenceTransformer

# Load a pre-trained embedding generation model
# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
model = SentenceTransformer("all-MiniLM-L6-v2")

# Initialize the database
db = kuzu.Database()
conn = kuzu.Connection(db)

# Install and load vector extension
conn.execute("INSTALL VECTOR;")
conn.execute("LOAD VECTOR;")

# Create tables
conn.execute("CREATE NODE TABLE Book(id SERIAL PRIMARY KEY, title STRING, title_embedding FLOAT[384], published_year INT64);")
conn.execute("CREATE NODE TABLE Publisher(name STRING PRIMARY KEY);")
conn.execute("CREATE REL TABLE PublishedBy(FROM Book TO Publisher);")

# Sample data
titles = ["The Quantum World", "Chronicles of the Universe", "Learning Machines", "Echoes of the Past", "The Dragon's Call"]
publishers = ["Harvard University Press", "Independent Publisher", "Pearson", "McGraw-Hill Ryerson", "O'Reilly"]
published_years = [2004, 2022, 2019, 2010, 2015]

# Insert sample data - Books with embeddings
for title, published_year in zip(titles, published_years):
    # Convert title to a 384-dimensional embedding vector
    embeddings = model.encode(title).tolist()
    conn.execute(
        """CREATE (b:Book {title: $title, title_embedding: $embeddings, published_year: $year});""",
        {"title": title, "embeddings": embeddings, "year": published_year}
    )

# Insert sample data - Publishers
for publisher in publishers:
    conn.execute(
        """CREATE (p:Publisher {name: $publisher});""",
        {"publisher": publisher}
    )

# Create relationships between Books and Publishers
for title, publisher in zip(titles, publishers):
    conn.execute("""
        MATCH (b:Book {title: $title})
        MATCH (p:Publisher {name: $publisher})
        CREATE (b)-[:PublishedBy]->(p);
    """, 
    {"title": title, "publisher": publisher}
    )
```

###

To create a vector index on the `title_embedding` column of the `Book` table, we can use the `CALL`
statement as follows:

```python
# Create vector index
conn.execute(
    """
    CALL CREATE_VECTOR_INDEX(
        'Book',
        'title_vec_index',
        'title_embedding'
    );
    """
)
```

We can now query the index to find the two books most similar to "The Quantum World".
```python
query_vector = model.encode("The Quantum World").tolist()
result = conn.execute(
    """
    CALL QUERY_VECTOR_INDEX(
        'Book',
        'title_vec_index',
        $query_vector,
        2
    )
    RETURN node.title ORDER BY distance;
    """,
    {"query_vector": query_vector})
print(result.get_as_df())
```
This returns:
```
                   node.title
0           The Quantum World
1  Chronicles of the Universe

```

Combining vector search with Cypher pattern matching is more useful when working in a graph database!
Let's find the publishers of the two books most similar to "The Quantum World".

```python
result = conn.execute(
    """
    CALL QUERY_VECTOR_INDEX('book', 'title_vec_index', $query_vector, 2)
    WITH node AS n, distance
    MATCH (n)-[:PublishedBy]->(p:Publisher)
    RETURN p.name AS publisher
    """,
    {"query_vector": query_vector})
print(result.get_as_df())
```
The above query first finds the two books most similar to "The Quantum World", and then matches the most similar books with the publishers, which is a regular graph traversal
in Cypher. This returns:
```
                  publisher
0  Harvard University Press
1     Independent Publisher
```

Using vector search in combination with graph traversals, we can now find relevant entry
points into our graph based on similarity search, which can be a powerful way to explore your graph data.

### Filtered vector search

One very useful feature of Kuzu's vector index is that it also supports performing vector search on a
subset of records (filtered search). To perform a filtered search, we use a [projected graph](https://docs.kuzudb.com/extensions/vector/#what-is-a-projected-graph)
to filter the records before performing the vector search.

A projected graph is a subgraph containing only nodes and relationships that match the given table names
and filters.  Currently, projected graphs support single node tables with simple property-based filters. 
More flexible filtering using Cypher variables will be supported in future versions.

Let's use a projected graph to find publishers of books similar to "The Quantum World"
published after 2010:

```python
# Create a projected graph with a filter on published_year of Book
# No relationship tables will be projected here
# That's why the final argument is an empty list
conn.execute(
    """
    CALL CREATE_PROJECTED_GRAPH(
        'filtered_book',
        {'Book': {'filter': 'n.published_year > 2010'}},
        []
    );
    """
)

query_vector = model.encode("The Quantum World").tolist()

# Query the index on the projected graph
result = conn.execute("""
    CALL QUERY_VECTOR_INDEX(
        'filtered_book',
        'title_vec_index',
        $query_vector,
        2
    )
    WITH node AS n, distance as dist 
    MATCH (n)-[:PublishedBy]->(p:Publisher)
    RETURN n.title AS book,
           n.published_year AS year,
           p.name AS publisher
    ORDER BY dist;
    """,
    {"query_vector": query_vector})
print(result.get_as_df())
```
This returns the following books that are most similar to the input query, and published after 2010:
```
                         book  year              publisher
0  Chronicles of the Universe  2022  Independent Publisher
1           Learning Machines  2019                Pearson
```

Filtered vector search makes it even simpler to find relevant records in your graph
that are semantically similar to a given query vector.

### Search performance

We evaluate the index construction and query performance on the [ann-benchmark](https://github.com/erikbern/ann-benchmarks).
The benchmark results shown below are from a Macbook Mini with an M4 Pro chip, 64GB RAM and a 1TB SSD.
Kuzu is run using "on-disk" or persistent mode and the maximum number of threads is set as **8**,

<!--The index is built with **8 threads**. -->
The table below summarizes index construction time and query latency across various datasets without any filters:
<!--
Each query is run through our Python API for 3 times, and we report the average latency.
The query template is as follows:
```python
conn.execute("""
    CALL QUERY_VECTOR_INDEX('project', 'tbl_vec_index', $q, 100) RETURN node.id, distance;
    """, {'q': vec})
```
-->
| Dataset | Dimension | Num tuples | Construction (s) | Query (ms) |
| --- | --- | --- | --- | --- |
| MNIST | 784 | 60,000 | 9.8 | 4.1 |
| SIFT | 128 | 100,000 | 11.6 | 5.0 |
| Glove-25 | 25 | 1,183,514 | 74.4 | 5.2 |
| Deep1B | 96 | 9,990,000 | 1691.8 | 7.9 |

It's clear from the above table that for the various datasets shown, average query latency is < 10 ms.

To evaluate filtered search performance, we apply a filter on the base table, sequentually increasing
its selectivity from 1% to 2%, and upwards to 90% as shown.
We randomly select 50 queries from the GIST query set. For each selectivity level, we apply the filter
using a projected graph and perform the search. The table below presents query latency and recall at different selectivity levels:
<!--
The index is built with **8 threads** under the setting (`mu := 32, ml := 64, efc := 200`), and queried with **single thread** under the default setting `efs := 200`.-->

| Selectivity (%) | Query (ms) | Recall |
| --- | --- | --- |
| 1 | 16.7 | 1.00 |
| 3 | 16.4 | 1.00 |
| 5 | 17.2 | 0.99 |
| 10 | 148.3 | 1.00 |
| 20 | 42.1 | 0.99 |
| 30 | 32.3 | 0.99 |
| 40 | 7.5 | 0.90 |
| 50 | 8.2 | 0.91 |
| 75 | 11.4 | 0.92 |
| 90 | 11.9 | 0.92 |

We can see that we're able to maintain a sufficiently high recall across different levels of selectivity.

### Current limitations

This inaugural release of the vector index comes with some limitations, which will be addressed in future releases:
- The index is currently **immutable** after creation - it must be dropped and re-created to reflect changes to the data in the underlying tables.
- We currently only support indexing over `FLOAT` (32-bit float) array columns in Kuzu. Support for 64-bit floats (`DOUBLE`) will be added in the next release.
- The index can currently only be created over a single column in node tables.

You can see our vector extension documentation [here](https://docs.kuzudb.com/extensions/vector/).

## Arbitrary SQL scans from Postgres databases

In a previous release, we introduced the [Postgres extension](https://docs.kuzudb.com/extensions/attach/rdbms/) which enabled scanning from PostgreSQL tables. This release further extends the capability with `SQL_QUERY` function, allowing users to execute arbitrary
read-only SQL queries on attached PostgreSQL databases and retrieve the query result in Kuzu.

An example is shown below:
```sql
-- Attach a Postgres database
ATTACH 'dbname=university user=postgres host=localhost password=yourpassword port=5432' AS uw (dbtype postgres);
-- Scan from a Postgres query
CALL SQL_QUERY('uw', 'SELECT id, name, age FROM person WHERE age > 20') RETURN *;
-- Bulk insert from a Postgres query
CREATE NODE TABLE person(id INT PRIMARY KEY, name STRING, age INT);
COPY person FROM SQL_QUERY('uw', 'SELECT id, name, age FROM person WHERE age > 20');
```

The ability to scan from arbitrary SQL queries is useful when you want to push down specific query workloads
that are easier to express in SQL to the Postgres database. You can see the documentation of this feature
[here](https://docs.kuzudb.com/extensions/attach/postgres/#5-scan-from-postgresql-tables-with-sql).

## WASM with bundled extensions

One limitation of the initial [Wasm version](https://docs.kuzudb.com/client-apis/wasm/) of Kuzu was the
lack of support for extensions. That meant that users couldn't access useful functionality like full-text search,
JSON support and vector search.

This release addresses that limitation by bundling the relevant extensions through static linking. The
following extensions are now bundled with our Wasm binaries:
- Full-text search (`fts`)
- JSON (`json`)
- Vector index (`vector`)

You can now use the `fts`, `json` and `vector` extensions in your Wasm applications with Kuzu!

## New APIs and Ecosystem Integrations

### Async Python API

This release introduces a new async API for Python users -- you can now easily integrate Kuzu with web frameworks like
FastAPI that may be using `asyncio` to manage database connections.

```py
import asyncio
import kuzu

db = kuzu.Database("test_db")
# create the async connection, the underlying connection pool will be automatically created and managed by the async connection
conn = kuzu.AsyncConnection(db, max_concurrent_queries=4, max_threads_per_query=4)

async def main():
async def main():
    # create a table
    await conn.execute("CREATE NODE TABLE person(ID INT64 PRIMARY KEY, age INT64)")
    await conn.execute("MERGE (p:person {ID: 0, age: 20})")
    await conn.execute("MERGE (p:person {ID: 1, age: 25})")
    await conn.execute("MERGE (p:person {ID: 2, age: 30})")
    
    # Run async queries via asyncio
    num_queries = 10
    queries = [f"MATCH (a:person {{ID: {i}}}) RETURN a.*;" for i in range(num_queries)]
    result = await asyncio.gather(*[conn.execute(query) for query in queries])
    for r in result:
        while r.has_next():
            print(r.get_next())
```

See the [Python client](https://docs.kuzudb.com/client-apis/python/#sync-and-async-apis) API docs
for more details.

### Sync Node.js API

For more feature completeness and for cases where a synchronous API is required, we now provide a
a synchronous API for our Node.js users. See the [Node.js client](https://docs.kuzudb.com/client-apis/nodejs/#sync-and-async-apis)
API docs for more details and an example.

### Unity Catalog integration

We already announced Kuzu's integration with Unity Catalog in our previous release post. We've recently
been added to their [OSS docs page](https://www.databricks.com/blog/2025/03/27/introducing-unity-catalog-partner-program.html),
so go there and check it out!

### MCP server implementation

There's recently been a frenzy of activity around the Model Context Protocol (MCP), an open protocol released by Anthropic
to standardize how LLMs interact with external tools. We're happy to contribute to this growing ecosystem, and Kuzu now provides an
[MCP server implementation](https://github.com/kuzudb/kuzu-mcp-server).

MCP clients like Claude Desktop and Cursor can now connect to Kuzu and use it as a database for storing,
querying and even debugging your graph data -- see our recent [blog post](https://blog.kuzudb.com/post/2025-03-23-kuzu-mcp-server/)
on an example of using Kuzu-MCP with Cursor.

### G.V() integration

We're excited to announce that Kuzu is now integrated with [G.V()](https://www.gdotv.com/), a graph
database client and visualization tool. You can now easily connect to Kuzu from G.V() and run
Cypher queries to explore your graph data in various ways, offering added capabilities to generate
custom graph visualizations on larger graphs. Check out the our [docs](https://docs.kuzudb.com/visualization/third-party-integrations/gdotv/)
and the [release announcement post](https://gdotv.com/blog/gdotv-kuzu-release-announcement/) on this new integration to learn more.

## Performance Improvements

Below, we list two benchmark results to showcase some of the performance improvements in this release.

### Aggregation

We've been focused on improving our aggregation performance in the last few releases starting from version 0.7.1, and this release
is no exception.
In this release, we further improved the performance of aggregation workloads, including distinct, hash aggregate and aggregate on distinct values. 
The performance gains mainly come from vectorizing the computation and paralleling the final aggregation stage.

The benchmark results below are a version of [ClickBench](https://github.com/ClickHouse/ClickBench/)'s benchmark suite
(which are aggregation-heavy), but adapted to use Cypher and run using a modified version of their benchmarking scripts.
We use our Python API to execute the queries and measures the total runtime of `kuzu.Connection.execute`).
We run each query twice from the same process, database and connection, and record the average query latency.
The queries were run on a machine with 2x AMD EPYC 7551 (total 64 cores 128 threads) and 512GB RAM.

| Query   | 0.7.1 (s)    | 0.8.0 (s)       | 0.8.2           | 0.9.0              |
|---------|--------------|-----------------|-----------------|--------------------|
| Q5      | 21           | 22.1            | 22.8            | 0.52 (**44x**)    |
| Q6      | 16.9         | 17.1            | 11              | 0.373 (**46x**)   |
| Q9      | 196          | 35.4 (6x)       | 2.46 (**79x**)  | 1.96 (**100x**)   |
| Q10     | 206          | 47.3 (4x)       | 2.62 (**79x**)  | 1.99 (**104x**)   |
| Q11     | 15           | 6.4 (2x)        | 0.681 (**22x**) | 0.633 (24x)   |
| Q12     | 28.6         | 6.88 (4x)       | 0.684 (**42x**) | 0.737 (39x)   |
| Q13     | 3.58         | 0.424 (**8x**)  | 0.427 (8x)      | 0.428 (8x)    |
| Q14     | 53           | 17.3 (3x)       | 0.903 (**59x**) | 0.879 (60x)   |
| Q15     | 4.03         | 0.458 (**9x**)  | 0.46 (9x)       | 0.446 (9x)    |
| Q16     | 5.99         | 0.75 (**8x**)   | 0.747 (8x)      | 0.749 (8x)    |
| Q17     | 8.36         | 1.01 (**8x**)   | 1.06 (8x)       | 1.05 (8x)     |
| Q18     | 9.13         | 0.922 (**10x**) | 1.06 (9x)       | 0.947 (10x)   |
| Q19     | 21           | 2.42 (**9x**)   | 2.72 (8x)       | 2.45 (9x)     |
| Q21     | 20.7         | 23.6            | 21.7            | 0.634 (**37x**)   |
| Q22     | 21           | 23.6            | 21.5            | 0.854 (**28x**)   |
| Q23     | 1.09e+03     | 1.11e+03        | 18.5 (**60x**)  | 0.949 (**1170x**) |
| Q24     | 22.5         | 24.6            | 23.1            | 3.24 (**8x**)     |
| Q31     | 3.47         | 0.526 (**7x**)  | 0.535 (6x)      | 0.544 (6x)    |
| Q32     | 5.36         | 0.771 (**7x**)  | 0.784 (7x)      | 0.787 (7x)    |
| Q33     | 48.7         | 6.22 (**8x**)   | 6.27 (8x)       | 6.38 (8x)     |
| Q34     | 15.8         | 1.67 (**9x**)   | 1.66 (10x)  | 1.66 (10x)    |
| Q35     | 17.9         | 1.75 (**10x**)  | 1.78 (10x)      | 1.8 (10x)     |
| Q36     | 7.84         | 0.946 (**8x**)  | 0.932 (8x)      | 0.898 (9x)    |

The above table shows query latency in seconds for each query in each of the previous 3 releases, in addition to this one.
The speedup numbers shown are relative to version `0.7.1`, when we first began these improvements.
For certain queries, we see up to a **1170x** speedup, and for many other queries, we achieve a **> 10x** speedup.
If you have any aggregation-heavy workloads that aren't performing as well as you'd like, please give our new
version a try and see if it helps! We'll continue improving the performance of our aggregation and other
core operators in upcoming releases.

### Full-text search index creation

We're happy to announce that the performance of our full-text search (FTS) index creation is 
significantly improved in this release. The following benchmark is run using `ms-passage` dataset
with 8.8M documents that take up 2.9GB of disk space on a machine with 2 AMD EPYC 7551 CPUs with 64
cores and 409GB of memory. 

| v0.8.0 (s) | v0.9.0 (s) | Speedup |
|--------|--------| ------- |
| 460   | 108   | **4.3x**    |

FTS index creation in v0.9.0 is **4.3x** faster than in v0.8.0! 🚀

## Conclusions

Whew! This release was most certainly packed with a ton features and improvements.
Along the way, we've also included numerous bug fixes to hopefully improve your experience and productivity when working with Kuzu.
We're grateful to our entire team of hardworking interns and core developers for
their awesome work on this release. And our sincere gratitude goes out to you, the user community,
for all your bug reports and feature requests! Please try out the new release and let us
know what you think.

Happy graph querying!

-- The Kuzu Team